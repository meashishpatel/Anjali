{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32ea06c-5293-4b61-9e1f-e170ca8b966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread  # Assuming you'll use skimage for reading Sentinel images\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29f1940-df8f-48fd-98ab-4c7a8ba813b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  no2Value  longitude   latitude regionName  day  month  year  \\\n",
      "0  2019-01-01  0.315386   77.30505  28.646846      Delhi    1      1  2019   \n",
      "1  2019-01-02  0.274257   77.30505  28.646846      Delhi    2      1  2019   \n",
      "2  2019-01-03  0.249579   77.30505  28.646846      Delhi    3      1  2019   \n",
      "3  2019-01-04  0.248769   77.30505  28.646846      Delhi    4      1  2019   \n",
      "4  2019-01-05  0.190129   77.30505  28.646846      Delhi    5      1  2019   \n",
      "\n",
      "   weekday  \n",
      "0        1  \n",
      "1        2  \n",
      "2        3  \n",
      "3        4  \n",
      "4        5  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load CSV data\n",
    "csv_file = 'delhi_data_2019.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b47842e-e545-4b85-bb0e-e980234f4859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-06-30.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-07-02.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-10-18.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-11-20.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-11-23.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-11-29.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-04.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-05.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-06.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-07.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-09.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-11.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-12.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-14.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-16.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-18.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-19.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-20.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-21.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-22.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-23.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-24.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-26.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-27.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-28.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-31.tif\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load Sentinel images\n",
    "image_folder = r\"C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\"\n",
    "\n",
    "def load_sentinel_image(date):\n",
    "    image_name = f'DelhiNO2{date.strftime(\"%Y-%m-%d\")}.tif'\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    try:\n",
    "        image = imread(image_path)\n",
    "        # Perform any preprocessing or feature extraction here\n",
    "        return image\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found - {image_path}\")\n",
    "        return None  # Or handle missing image case as per your requirement\n",
    "\n",
    "# Convert 'year', 'month', 'day' columns to datetime\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# Apply load_sentinel_image function to create 'image' column\n",
    "df['image'] = df['date'].apply(lambda x: load_sentinel_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5353d0-4437-435d-8f6b-37595944726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Engineering\n",
    "def calculate_image_stats(image):\n",
    "    if image is not None:\n",
    "        # Calculate statistics from the image (example: mean, standard deviation, etc.)\n",
    "        mean_value = np.mean(image)\n",
    "        std_value = np.std(image)\n",
    "        max_value = np.max(image)\n",
    "        min_value = np.min(image)\n",
    "        return mean_value, std_value, max_value, min_value\n",
    "    else:\n",
    "        return None, None, None, None\n",
    "\n",
    "# Apply feature extraction to each image and create new columns\n",
    "df['mean_pixel'], df['std_pixel'], df['max_pixel'], df['min_pixel'] = zip(*df['image'].apply(calculate_image_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979b2f6c-bafd-40c1-9657-ffbbbe4eb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare data for model training\n",
    "X = df[['mean_pixel', 'std_pixel', 'max_pixel', 'min_pixel']]  # Features used for prediction\n",
    "y = df['no2Value']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc473ce4-c75b-4b40-bcdb-24279bd7a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by GridSearchCV:\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train a regression model (Example: Random Forest Regressor)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Use the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69713192-2f85-4714-86c2-c02b9fb23cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 Score: 0.6172050546529642\n",
      "Testing R2 Score: 0.35261255773395817\n",
      "Training RMSE: 0.033260382414128514\n",
      "Testing RMSE: 0.046510780077743084\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "print(f\"Training R2 Score: {train_r2}\")\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"Testing R2 Score: {test_r2}\")\n",
    "\n",
    "# Additional evaluation metrics (RMSE)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(f\"Training RMSE: {train_rmse}\")\n",
    "print(f\"Testing RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c06fcc7-079d-436e-ba51-7fc6aedfa11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted NO2 value for 2019-01-01: 0.2765728429128043\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Predict NO2 value for a specific date\n",
    "date_of_interest = pd.to_datetime('2019-01-01')\n",
    "image_of_interest = load_sentinel_image(date_of_interest)\n",
    "\n",
    "if image_of_interest is not None:\n",
    "    mean_val, std_val, max_val, min_val = calculate_image_stats(image_of_interest.reshape(-1))  # Reshape image for stats\n",
    "    prediction_input = pd.DataFrame({\n",
    "        'mean_pixel': [mean_val],\n",
    "        'std_pixel': [std_val],\n",
    "        'max_pixel': [max_val],\n",
    "        'min_pixel': [min_val]\n",
    "    })\n",
    "\n",
    "    predicted_no2 = best_model.predict(prediction_input)\n",
    "    print(f\"Predicted NO2 value for {date_of_interest.date()}: {predicted_no2[0]}\")\n",
    "else:\n",
    "    print(f\"No image found for {date_of_interest.date()}. Prediction cannot be made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd3e5c-335b-4fad-a086-38c994c94813",
   "metadata": {},
   "source": [
    "# This is second trial of another model having r2 score of 2 ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae4bca43-baa9-4e1a-aff0-3c2471bde63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-06-30.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-07-02.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-10-18.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-11-20.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-11-23.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-11-29.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-04.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-05.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-06.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-07.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-09.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-11.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-12.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-14.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-16.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-18.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-19.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-20.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-21.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-22.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-23.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-24.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-26.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-27.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-28.tif\n",
      "Warning: File not found - C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\\DelhiNO22019-12-31.tif\n",
      "R2 Score: 0.0963632540273317\n",
      "Predictions: [0.1678295  0.24421542 0.20423371]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread  # Assuming you'll use skimage for reading Sentinel images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "csv_file = 'delhi_data_2019.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Step 2: Load Sentinel images\n",
    "image_folder = r\"C:\\Users\\ashis\\Desktop\\Anjali\\ImageData\\2019\\Delhi_NO2\"\n",
    "\n",
    "def load_sentinel_image(date):\n",
    "    image_name = f'DelhiNO2{date.strftime(\"%Y-%m-%d\")}.tif'\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    try:\n",
    "        image = imread(image_path)\n",
    "        # Perform any preprocessing or feature extraction here\n",
    "        return image\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found - {image_path}\")\n",
    "        return None  # Or handle missing image case as per your requirement\n",
    "\n",
    "# Convert 'year', 'month', 'day' columns to datetime\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# Apply load_sentinel_image function to create 'image' column\n",
    "df['image'] = df['date'].apply(lambda x: load_sentinel_image(x))\n",
    "\n",
    "# Step 3: Feature Engineering (Example: Calculate mean pixel value as a feature)\n",
    "def calculate_mean_pixel(image):\n",
    "    if image is not None:\n",
    "        return image.mean()  # Example feature extraction, modify as per your requirement\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['mean_pixel_value'] = df['image'].apply(calculate_mean_pixel)\n",
    "\n",
    "# Step 4: Prepare data for model training\n",
    "X = df[['mean_pixel_value']]  # Feature(s) used for prediction\n",
    "y = df['no2Value']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train a regression model (Example: Random Forest Regressor)\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2 Score: {r2}\")\n",
    "\n",
    "# Step 7: Optionally, use the trained model for predictions on new data\n",
    "# Example:\n",
    "new_data = pd.DataFrame({'mean_pixel_value': [100.0, 120.0, 90.0]})\n",
    "predictions = model.predict(new_data)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15067129-a907-4c86-9b06-0be20a6272cc",
   "metadata": {},
   "source": [
    "# Till this was 2 model completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
